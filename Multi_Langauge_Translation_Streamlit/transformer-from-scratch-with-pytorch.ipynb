{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-01-02T20:36:36.343359Z","iopub.status.busy":"2024-01-02T20:36:36.342995Z","iopub.status.idle":"2024-01-02T20:36:50.854538Z","shell.execute_reply":"2024-01-02T20:36:50.853734Z","shell.execute_reply.started":"2024-01-02T20:36:36.343328Z"},"trusted":true},"outputs":[],"source":["# Importing libraries\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# Math\n","import math\n","\n","# HuggingFace libraries \n","from datasets import load_dataset\n","from tokenizers import Tokenizer\n","from tokenizers.models import WordLevel\n","from tokenizers.trainers import WordLevelTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","\n","# Pathlib \n","from pathlib import Path\n","\n","# typing\n","from typing import Any\n","\n","# Library for progress bars in loops\n","from tqdm import tqdm\n","\n","# Importing library of warnings\n","import warnings"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-02T20:36:50.856809Z","iopub.status.busy":"2024-01-02T20:36:50.856257Z","iopub.status.idle":"2024-01-02T20:36:50.862511Z","shell.execute_reply":"2024-01-02T20:36:50.861634Z","shell.execute_reply.started":"2024-01-02T20:36:50.856779Z"},"trusted":true},"outputs":[],"source":["# Creating Input Embeddings\n","class InputEmbeddings(nn.Module):\n","    \n","    def __init__(self, d_model: int, vocab_size: int):\n","        super().__init__()\n","        self.d_model = d_model # Dimension of vectors (512)\n","        self.vocab_size = vocab_size # Size of the vocabulary\n","        self.embedding = nn.Embedding(vocab_size, d_model) # PyTorch layer that converts integer indices to dense embeddings\n","        \n","    def forward(self, x):\n","        return self.embedding(x) * math.sqrt(self.d_model) # Normalizing the variance of the embeddings"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-02T20:36:50.863866Z","iopub.status.busy":"2024-01-02T20:36:50.863608Z","iopub.status.idle":"2024-01-02T20:36:50.898626Z","shell.execute_reply":"2024-01-02T20:36:50.897813Z","shell.execute_reply.started":"2024-01-02T20:36:50.863843Z"},"trusted":true},"outputs":[],"source":["# Creating the Positional Encoding\n","class PositionalEncoding(nn.Module):\n","    \n","    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n","        super().__init__()\n","        self.d_model = d_model # Dimensionality of the model\n","        self.seq_len = seq_len # Maximum sequence length\n","        self.dropout = nn.Dropout(dropout) # Dropout layer to prevent overfitting\n","        \n","        # Creating a positional encoding matrix of shape (seq_len, d_model) filled with zeros\n","        pe = torch.zeros(seq_len, d_model) \n","        \n","        # Creating a tensor representing positions (0 to seq_len - 1)\n","        position = torch.arange(0, seq_len, dtype = torch.float).unsqueeze(1) # Transforming 'position' into a 2D tensor['seq_len, 1']\n","        \n","        # Creating the division term for the positional encoding formula\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        \n","        # Apply sine to even indices in pe\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        # Apply cosine to odd indices in pe\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        \n","        # Adding an extra dimension at the beginning of pe matrix for batch handling\n","        pe = pe.unsqueeze(0)\n","        \n","        # Registering 'pe' as buffer. Buffer is a tensor not considered as a model parameter\n","        self.register_buffer('pe', pe) \n","        \n","    def forward(self,x):\n","        # Addind positional encoding to the input tensor X\n","        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n","        return self.dropout(x) # Dropout for regularization"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-02T20:36:50.899897Z","iopub.status.busy":"2024-01-02T20:36:50.899651Z","iopub.status.idle":"2024-01-02T20:36:50.913256Z","shell.execute_reply":"2024-01-02T20:36:50.912406Z","shell.execute_reply.started":"2024-01-02T20:36:50.899875Z"},"trusted":true},"outputs":[],"source":["# Creating Layer Normalization\n","class LayerNormalization(nn.Module):\n","    \n","    def __init__(self, eps: float = 10**-6) -> None: # We define epsilon as 0.000001 to avoid division by zero\n","        super().__init__()\n","        self.eps = eps\n","        \n","        # We define alpha as a trainable parameter and initialize it with ones\n","        self.alpha = nn.Parameter(torch.ones(1)) # One-dimensional tensor that will be used to scale the input data\n","        \n","        # We define bias as a trainable parameter and initialize it with zeros\n","        self.bias = nn.Parameter(torch.zeros(1)) # One-dimensional tenso that will be added to the input data\n","        \n","    def forward(self, x):\n","        mean = x.mean(dim = -1, keepdim = True) # Computing the mean of the input data. Keeping the number of dimensions unchanged\n","        std = x.std(dim = -1, keepdim = True) # Computing the standard deviation of the input data. Keeping the number of dimensions unchanged\n","        \n","        # Returning the normalized input\n","        return self.alpha * (x-mean) / (std + self.eps) + self.bias"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Creating Feed Forward Layers\n","class FeedForwardBlock(nn.Module):\n","    \n","    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n","        super().__init__()\n","        # First linear transformation\n","        self.linear_1 = nn.Linear(d_model, d_ff) # W1 & b1\n","        self.dropout = nn.Dropout(dropout) # Dropout to prevent overfitting\n","        # Second linear transformation\n","        self.linear_2 = nn.Linear(d_ff, d_model) # W2 & b2\n","        \n","    def forward(self, x):\n","        # (Batch, seq_len, d_model) --> (batch, seq_len, d_ff) -->(batch, seq_len, d_model)\n","        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Creating the Multi-Head Attention block\n","class MultiHeadAttentionBlock(nn.Module):\n","    \n","    def __init__(self, d_model: int, h: int, dropout: float) -> None: # h = number of heads\n","        super().__init__()\n","        self.d_model = d_model\n","        self.h = h\n","        \n","        # We ensure that the dimensions of the model is divisible by the number of heads\n","        assert d_model % h == 0, 'd_model is not divisible by h'\n","        \n","        # d_k is the dimension of each attention head's key, query, and value vectors\n","        self.d_k = d_model // h # d_k formula, like in the original \"Attention Is All You Need\" paper\n","        \n","        # Defining the weight matrices\n","        self.w_q = nn.Linear(d_model, d_model) # W_q\n","        self.w_k = nn.Linear(d_model, d_model) # W_k\n","        self.w_v = nn.Linear(d_model, d_model) # W_v\n","        self.w_o = nn.Linear(d_model, d_model) # W_o\n","        \n","        self.dropout = nn.Dropout(dropout) # Dropout layer to avoid overfitting\n","        \n","    \n","    @staticmethod\n","    def attention(query, key, value, mask, dropout: nn.Dropout):# mask => When we want certain words to NOT interact with others, we \"hide\" them\n","        \n","        d_k = query.shape[-1] # The last dimension of query, key, and value\n","        \n","        # We calculate the Attention(Q,K,V) as in the formula in the image above \n","        attention_scores = (query @ key.transpose(-2,-1)) / math.sqrt(d_k) # @ = Matrix multiplication sign in PyTorch\n","        \n","        # Before applying the softmax, we apply the mask to hide some interactions between words\n","        if mask is not None: # If a mask IS defined...\n","            attention_scores.masked_fill_(mask == 0, -1e9) # Replace each value where mask is equal to 0 by -1e9\n","        attention_scores = attention_scores.softmax(dim = -1) # Applying softmax\n","        if dropout is not None: # If a dropout IS defined...\n","            attention_scores = dropout(attention_scores) # We apply dropout to prevent overfitting\n","            \n","        return (attention_scores @ value), attention_scores # Multiply the output matrix by the V matrix, as in the formula\n","        \n","    def forward(self, q, k, v, mask): \n","        \n","        query = self.w_q(q) # Q' matrix\n","        key = self.w_k(k) # K' matrix\n","        value = self.w_v(v) # V' matrix\n","        \n","        \n","        # Splitting results into smaller matrices for the different heads\n","        # Splitting embeddings (third dimension) into h parts\n","        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2) # Transpose => bring the head to the second dimension\n","        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2) # Transpose => bring the head to the second dimension\n","        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2) # Transpose => bring the head to the second dimension\n","        \n","        # Obtaining the output and the attention scores\n","        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n","        \n","        # Obtaining the H matrix\n","        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n","        \n","        return self.w_o(x) # Multiply the H matrix by the weight matrix W_o, resulting in the MH-A matrix"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Building Residual Connection\n","class ResidualConnection(nn.Module):\n","    def __init__(self, dropout: float) -> None:\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout) # We use a dropout layer to prevent overfitting\n","        self.norm = LayerNormalization() # We use a normalization layer \n","    \n","    def forward(self, x, sublayer):\n","        # We normalize the input and add it to the original input 'x'. This creates the residual connection process.\n","        return x + self.dropout(sublayer(self.norm(x))) "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Building Encoder Block\n","class EncoderBlock(nn.Module):\n","    \n","    # This block takes in the MultiHeadAttentionBlock and FeedForwardBlock, as well as the dropout rate for the residual connections\n","    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n","        super().__init__()\n","        # Storing the self-attention block and feed-forward block\n","        self.self_attention_block = self_attention_block\n","        self.feed_forward_block = feed_forward_block\n","        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)]) # 2 Residual Connections with dropout\n","        \n","    def forward(self, x, src_mask):\n","        # Applying the first residual connection with the self-attention block\n","        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask)) # Three 'x's corresponding to query, key, and value inputs plus source mask\n","        \n","        # Applying the second residual connection with the feed-forward block \n","        x = self.residual_connections[1](x, self.feed_forward_block)\n","        return x # Output tensor after applying self-attention and feed-forward layers with residual connections."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Building Encoder \n","# An Encoder can have several Encoder Blocks\n","class Encoder(nn.Module):\n","    \n","    # The Encoder takes in instances of 'EncoderBlock'\n","    def __init__(self, layers: nn.ModuleList) -> None:\n","        super().__init__()\n","        self.layers = layers # Storing the EncoderBlocks\n","        self.norm = LayerNormalization() # Layer for the normalization of the output of the encoder layers\n","        \n","    def forward(self, x, mask):\n","        # Iterating over each EncoderBlock stored in self.layers\n","        for layer in self.layers:\n","            x = layer(x, mask) # Applying each EncoderBlock to the input tensor 'x'\n","        return self.norm(x) # Normalizing output"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Building Decoder Block\n","class DecoderBlock(nn.Module):\n","    \n","    # The DecoderBlock takes in two MultiHeadAttentionBlock. One is self-attention, while the other is cross-attention.\n","    # It also takes in the feed-forward block and the dropout rate\n","    def __init__(self,  self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n","        super().__init__()\n","        self.self_attention_block = self_attention_block\n","        self.cross_attention_block = cross_attention_block\n","        self.feed_forward_block = feed_forward_block\n","        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)]) # List of three Residual Connections with dropout rate\n","        \n","    def forward(self, x, encoder_output, src_mask, tgt_mask):\n","        \n","        # Self-Attention block with query, key, and value plus the target language mask\n","        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n","        \n","        # The Cross-Attention block using two 'encoder_ouput's for key and value plus the source language mask. It also takes in 'x' for Decoder queries\n","        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n","        \n","        # Feed-forward block with residual connections\n","        x = self.residual_connections[2](x, self.feed_forward_block)\n","        return x"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Building Decoder\n","# A Decoder can have several Decoder Blocks\n","class Decoder(nn.Module):\n","    \n","    # The Decoder takes in instances of 'DecoderBlock'\n","    def __init__(self, layers: nn.ModuleList) -> None:\n","        super().__init__()\n","        \n","        # Storing the 'DecoderBlock's\n","        self.layers = layers\n","        self.norm = LayerNormalization() # Layer to normalize the output\n","        \n","    def forward(self, x, encoder_output, src_mask, tgt_mask):\n","        \n","        # Iterating over each DecoderBlock stored in self.layers\n","        for layer in self.layers:\n","            # Applies each DecoderBlock to the input 'x' plus the encoder output and source and target masks\n","            x = layer(x, encoder_output, src_mask, tgt_mask)\n","        return self.norm(x) # Returns normalized output"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Buiding Linear Layer\n","class ProjectionLayer(nn.Module):\n","    def __init__(self, d_model: int, vocab_size: int) -> None: # Model dimension and the size of the output vocabulary\n","        super().__init__()\n","        self.proj = nn.Linear(d_model, vocab_size) # Linear layer for projecting the feature space of 'd_model' to the output space of 'vocab_size'\n","    def forward(self, x):\n","        return torch.log_softmax(self.proj(x), dim = -1) # Applying the log Softmax function to the output"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Creating the Transformer Architecture\n","class Transformer(nn.Module):\n","    \n","    # This takes in the encoder and decoder, as well the embeddings for the source and target language.\n","    # It also takes in the Positional Encoding for the source and target language, as well as the projection layer\n","    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.tgt_embed = tgt_embed\n","        self.src_pos = src_pos\n","        self.tgt_pos = tgt_pos\n","        self.projection_layer = projection_layer\n","        \n","    # Encoder     \n","    def encode(self, src, src_mask):\n","        src = self.src_embed(src) # Applying source embeddings to the input source language\n","        src = self.src_pos(src) # Applying source positional encoding to the source embeddings\n","        return self.encoder(src, src_mask) # Returning the source embeddings plus a source mask to prevent attention to certain elements\n","    \n","    # Decoder\n","    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n","        tgt = self.tgt_embed(tgt) # Applying target embeddings to the input target language (tgt)\n","        tgt = self.tgt_pos(tgt) # Applying target positional encoding to the target embeddings\n","        \n","        # Returning the target embeddings, the output of the encoder, and both source and target masks\n","        # The target mask ensures that the model won't 'see' future elements of the sequence\n","        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n","    \n","    # Applying Projection Layer with the Softmax function to the Decoder output\n","    def project(self, x):\n","        return self.projection_layer(x)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Building & Initializing Transformer\n","\n","# Definin function and its parameter, including model dimension, number of encoder and decoder stacks, heads, etc.\n","def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 8, dropout: float = 0.1, d_ff: int = 2048) -> Transformer:\n","    \n","    # Creating Embedding layers\n","    src_embed = InputEmbeddings(d_model, src_vocab_size) # Source language (Source Vocabulary to 512-dimensional vectors)\n","    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size) # Target language (Target Vocabulary to 512-dimensional vectors)\n","    \n","    # Creating Positional Encoding layers\n","    src_pos = PositionalEncoding(d_model, src_seq_len, dropout) # Positional encoding for the source language embeddings\n","    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout) # Positional encoding for the target language embeddings\n","    \n","    # Creating EncoderBlocks\n","    encoder_blocks = [] # Initial list of empty EncoderBlocks\n","    for _ in range(N): # Iterating 'N' times to create 'N' EncoderBlocks (N = 6)\n","        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout) # Self-Attention\n","        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout) # FeedForward\n","        \n","        # Combine layers into an EncoderBlock\n","        encoder_block = EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)\n","        encoder_blocks.append(encoder_block) # Appending EncoderBlock to the list of EncoderBlocks\n","        \n","    # Creating DecoderBlocks\n","    decoder_blocks = [] # Initial list of empty DecoderBlocks\n","    for _ in range(N): # Iterating 'N' times to create 'N' DecoderBlocks (N = 6)\n","        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout) # Self-Attention\n","        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout) # Cross-Attention\n","        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout) # FeedForward\n","        \n","        # Combining layers into a DecoderBlock\n","        decoder_block = DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n","        decoder_blocks.append(decoder_block) # Appending DecoderBlock to the list of DecoderBlocks\n","        \n","    # Creating the Encoder and Decoder by using the EncoderBlocks and DecoderBlocks lists\n","    encoder = Encoder(nn.ModuleList(encoder_blocks))\n","    decoder = Decoder(nn.ModuleList(decoder_blocks))\n","    \n","    # Creating projection layer\n","    projection_layer = ProjectionLayer(d_model, tgt_vocab_size) # Map the output of Decoder to the Target Vocabulary Space\n","    \n","    # Creating the transformer by combining everything above\n","    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n","    \n","    # Initialize the parameters\n","    for p in transformer.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","            \n","    return transformer # Assembled and initialized Transformer. Ready to be trained and validated!"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Defining Tokenizer\n","def build_tokenizer(config, ds, lang):\n","    \n","    # Crating a file path for the tokenizer \n","    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n","    \n","    # Checking if Tokenizer already exists\n","    if not Path.exists(tokenizer_path): \n","        \n","        # If it doesn't exist, we create a new one\n","        tokenizer = Tokenizer(WordLevel(unk_token = '[UNK]')) # Initializing a new world-level tokenizer\n","        tokenizer.pre_tokenizer = Whitespace() # We will split the text into tokens based on whitespace\n","        \n","        # Creating a trainer for the new tokenizer\n","        trainer = WordLevelTrainer(special_tokens = [\"[UNK]\", \"[PAD]\", \n","                                                     \"[SOS]\", \"[EOS]\"], min_frequency = 2) # Defining Word Level strategy and special tokens\n","        \n","        # Training new tokenizer on sentences from the dataset and language specified \n","        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer = trainer)\n","        tokenizer.save(str(tokenizer_path)) # Saving trained tokenizer to the file path specified at the beginning of the function\n","    else:\n","        tokenizer = Tokenizer.from_file(str(tokenizer_path)) # If the tokenizer already exist, we load it\n","    return tokenizer # Returns the loaded tokenizer or the trained tokenizer"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Iterating through dataset to extract the original sentence and its translation \n","def get_all_sentences(ds, lang):\n","    for pair in ds:\n","        yield pair['translation'][lang]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def get_ds(config):\n","    \n","    # Loading the train portion of the OpusBooks dataset.\n","    # The Language pairs will be defined in the 'config' dictionary we will build later\n","    ds_raw = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split = 'train') \n","    \n","    # Building or loading tokenizer for both the source and target languages \n","    tokenizer_src = build_tokenizer(config, ds_raw, config['lang_src'])\n","    tokenizer_tgt = build_tokenizer(config, ds_raw, config['lang_tgt'])\n","    \n","    # Splitting the dataset for training and validation \n","    train_ds_size = int(0.9 * len(ds_raw)) # 90% for training\n","    val_ds_size = len(ds_raw) - train_ds_size # 10% for validation\n","    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size]) # Randomly splitting the dataset\n","                                    \n","    # Processing data with the BilingualDataset class, which we will define below\n","    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n","    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n","                                    \n","    # Iterating over the entire dataset and printing the maximum length found in the sentences of both the source and target languages\n","    max_len_src = 0\n","    max_len_tgt = 0\n","    for pair in ds_raw:\n","        src_ids = tokenizer_src.encode(pair['translation'][config['lang_src']]).ids\n","        tgt_ids = tokenizer_src.encode(pair['translation'][config['lang_tgt']]).ids\n","        max_len_src = max(max_len_src, len(src_ids))\n","        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n","        \n","    print(f'Max length of source sentence: {max_len_src}')\n","    print(f'Max length of target sentence: {max_len_tgt}')\n","    \n","    # Creating dataloaders for the training and validadion sets\n","    # Dataloaders are used to iterate over the dataset in batches during training and validation\n","    train_dataloader = DataLoader(train_ds, batch_size = config['batch_size'], shuffle = True) # Batch size will be defined in the config dictionary\n","    val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)\n","    \n","    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt # Returning the DataLoader objects and tokenizers"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def casual_mask(size):\n","        # Creating a square matrix of dimensions 'size x size' filled with ones\n","        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n","        return mask == 0"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class BilingualDataset(Dataset):\n","    \n","    # This takes in the dataset contaning sentence pairs, the tokenizers for target and source languages, and the strings of source and target languages\n","    # 'seq_len' defines the sequence length for both languages\n","    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n","        super().__init__()\n","        \n","        self.seq_len = seq_len\n","        self.ds = ds\n","        self.tokenizer_src = tokenizer_src\n","        self.tokenizer_tgt = tokenizer_tgt\n","        self.src_lang = src_lang\n","        self.tgt_lang = tgt_lang\n","        \n","        # Defining special tokens by using the target language tokenizer\n","        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n","        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n","        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n","\n","        \n","    # Total number of instances in the dataset (some pairs are larger than others)\n","    def __len__(self):\n","        return len(self.ds)\n","    \n","    # Using the index to retrive source and target texts\n","    def __getitem__(self, index: Any) -> Any:\n","        src_target_pair = self.ds[index]\n","        src_text = src_target_pair['translation'][self.src_lang]\n","        tgt_text = src_target_pair['translation'][self.tgt_lang]\n","        \n","        # Tokenizing source and target texts \n","        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n","        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n","        \n","        # Computing how many padding tokens need to be added to the tokenized texts \n","        # Source tokens\n","        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2 # Subtracting the two '[EOS]' and '[SOS]' special tokens\n","        # Target tokens\n","        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1 # Subtracting the '[SOS]' special token\n","        \n","        # If the texts exceed the 'seq_len' allowed, it will raise an error. This means that one of the sentences in the pair is too long to be processed\n","        # given the current sequence length limit (this will be defined in the config dictionary below)\n","        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n","            raise ValueError('Sentence is too long')\n","         \n","        # Building the encoder input tensor by combining several elements\n","        encoder_input = torch.cat(\n","            [\n","            self.sos_token, # inserting the '[SOS]' token\n","            torch.tensor(enc_input_tokens, dtype = torch.int64), # Inserting the tokenized source text\n","            self.eos_token, # Inserting the '[EOS]' token\n","            torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n","            ]\n","        )\n","        \n","        # Building the decoder input tensor by combining several elements\n","        decoder_input = torch.cat(\n","            [\n","                self.sos_token, # inserting the '[SOS]' token \n","                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Addind padding tokens\n","            ]\n","        \n","        )\n","        \n","        # Creating a label tensor, the expected output for training the model\n","        label = torch.cat(\n","            [\n","                torch.tensor(dec_input_tokens, dtype = torch.int64), # Inserting the tokenized target text\n","                self.eos_token, # Inserting the '[EOS]' token \n","                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype = torch.int64) # Adding padding tokens\n","                \n","            ]\n","        )\n","        \n","        # Ensuring that the length of each tensor above is equal to the defined 'seq_len'\n","        assert encoder_input.size(0) == self.seq_len\n","        assert decoder_input.size(0) == self.seq_len\n","        assert label.size(0) == self.seq_len\n","        \n","        return {\n","            'encoder_input': encoder_input,\n","            'decoder_input': decoder_input, \n","            'encoder_mask': (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n","            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & casual_mask(decoder_input.size(0)), \n","            'label': label,\n","            'src_text': src_text,\n","            'tgt_text': tgt_text\n","        }    "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Define function to obtain the most probable next token\n","def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n","    # Retrieving the indices from the start and end of sequences of the target tokens\n","    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n","    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n","    \n","    # Computing the output of the encoder for the source sequence\n","    encoder_output = model.encode(source, source_mask)\n","    # Initializing the decoder input with the Start of Sentence token\n","    decoder_input = torch.empty(1,1).fill_(sos_idx).type_as(source).to(device)\n","    \n","    # Looping until the 'max_len', maximum length, is reached\n","    while True:\n","        if decoder_input.size(1) == max_len:\n","            break\n","            \n","        # Building a mask for the decoder input\n","        decoder_mask = casual_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n","        \n","        # Calculating the output of the decoder\n","        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n","        \n","        # Applying the projection layer to get the probabilities for the next token\n","        prob = model.project(out[:, -1])\n","        \n","        # Selecting token with the highest probability\n","        _, next_word = torch.max(prob, dim=1)\n","        decoder_input = torch.cat([decoder_input, torch.empty(1,1). type_as(source).fill_(next_word.item()).to(device)], dim=1)\n","        \n","        # If the next token is an End of Sentence token, we finish the loop\n","        if next_word == eos_idx:\n","            break\n","            \n","    return decoder_input.squeeze(0) # Sequence of tokens generated by the decoder"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Defining function to evaluate the model on the validation dataset\n","# num_examples = 2, two examples per run\n","def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=2):\n","    model.eval() # Setting model to evaluation mode\n","    count = 0 # Initializing counter to keep track of how many examples have been processed\n","    \n","    console_width = 80 # Fixed witdh for printed messages\n","    \n","    # Creating evaluation loop\n","    with torch.no_grad(): # Ensuring that no gradients are computed during this process\n","        for batch in validation_ds:\n","            count += 1\n","            encoder_input = batch['encoder_input'].to(device)\n","            encoder_mask = batch['encoder_mask'].to(device)\n","            \n","            # Ensuring that the batch_size of the validation set is 1\n","            assert encoder_input.size(0) ==  1, 'Batch size must be 1 for validation.'\n","            \n","            # Applying the 'greedy_decode' function to get the model's output for the source text of the input batch\n","            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n","            \n","            # Retrieving source and target texts from the batch\n","            source_text = batch['src_text'][0]\n","            target_text = batch['tgt_text'][0] # True translation \n","            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy()) # Decoded, human-readable model output\n","            \n","            # Printing results\n","            print_msg('-'*console_width)\n","            print_msg(f'SOURCE: {source_text}')\n","            print_msg(f'TARGET: {target_text}')\n","            print_msg(f'PREDICTED: {model_out_text}')\n","            \n","            # After two examples, we break the loop\n","            if count == num_examples:\n","                break"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# We pass as parameters the config dictionary, the length of the vocabylary of the source language and the target language\n","def get_model(config, vocab_src_len, vocab_tgt_len):\n","    \n","    # Loading model using the 'build_transformer' function.\n","    # We will use the lengths of the source language and target language vocabularies, the 'seq_len', and the dimensionality of the embeddings\n","    model = build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n","    return model"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Define settings for building and training the transformer model\n","def get_config():\n","    return{\n","        'batch_size': 8,\n","        'num_epochs': 20,\n","        'lr': 10**-4,\n","        'seq_len': 350,\n","        'd_model': 512, # Dimensions of the embeddings in the Transformer. 512 like in the \"Attention Is All You Need\" paper.\n","        'lang_src': 'en',\n","        'lang_tgt': 'it',\n","        'model_folder': 'weights',\n","        'model_basename': 'tmodel_',\n","        'preload': None,\n","        'tokenizer_file': 'tokenizer_{0}.json',\n","        'experiment_name': 'runs/tmodel'\n","    }\n","    \n","\n","# Function to construct the path for saving and retrieving model weights\n","def get_weights_file_path(config, epoch: str):\n","    model_folder = config['model_folder'] # Extracting model folder from the config\n","    model_basename = config['model_basename'] # Extracting the base name for model files\n","    model_filename = f\"{model_basename}{epoch}.pt\" # Building filename\n","    return str(Path('.')/ model_folder/ model_filename) # Combining current directory, the model folder, and the model filename"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def train_model(config):\n","    # Setting up device to run on GPU to train faster\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using device {device}\")\n","    \n","    # Creating model directory to store weights\n","    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n","    \n","    # Retrieving dataloaders and tokenizers for source and target languages using the 'get_ds' function\n","    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n","    \n","    # Initializing model on the GPU using the 'get_model' function\n","    model = get_model(config,tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n","    \n","    # Tensorboard\n","    writer = SummaryWriter(config['experiment_name'])\n","    \n","    # Setting up the Adam optimizer with the specified learning rate from the '\n","    # config' dictionary plus an epsilon value\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps = 1e-9)\n","    \n","    # Initializing epoch and global step variables\n","    initial_epoch = 0\n","    global_step = 0\n","    \n","    # Checking if there is a pre-trained model to load\n","    # If true, loads it\n","    if config['preload']:\n","        model_filename = get_weights_file_path(config, config['preload'])\n","        print(f'Preloading model {model_filename}')\n","        state = torch.load(model_filename) # Loading model\n","        \n","        # Sets epoch to the saved in the state plus one, to resume from where it stopped\n","        initial_epoch = state['epoch'] + 1\n","        # Loading the optimizer state from the saved model\n","        optimizer.load_state_dict(state['optimizer_state_dict'])\n","        # Loading the global step state from the saved model\n","        global_step = state['global_step']\n","        \n","    # Initializing CrossEntropyLoss function for training\n","    # We ignore padding tokens when computing loss, as they are not relevant for the learning process\n","    # We also apply label_smoothing to prevent overfitting\n","    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_src.token_to_id('[PAD]'), label_smoothing = 0.1).to(device)\n","    \n","    # Initializing training loop \n","    \n","    # Iterating over each epoch from the 'initial_epoch' variable up to\n","    # the number of epochs informed in the config\n","    for epoch in range(initial_epoch, config['num_epochs']):\n","        \n","        # Initializing an iterator over the training dataloader\n","        # We also use tqdm to display a progress bar\n","        batch_iterator = tqdm(train_dataloader, desc = f'Processing epoch {epoch:02d}')\n","        \n","        # For each batch...\n","        for batch in batch_iterator:\n","            model.train() # Train the model\n","            \n","            # Loading input data and masks onto the GPU\n","            encoder_input = batch['encoder_input'].to(device)\n","            decoder_input = batch['decoder_input'].to(device)\n","            encoder_mask = batch['encoder_mask'].to(device)\n","            decoder_mask = batch['decoder_mask'].to(device)\n","            \n","            # Running tensors through the Transformer\n","            encoder_output = model.encode(encoder_input, encoder_mask)\n","            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n","            proj_output = model.project(decoder_output)\n","            \n","            # Loading the target labels onto the GPU\n","            label = batch['label'].to(device)\n","            \n","            # Computing loss between model's output and true labels\n","            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n","            \n","            # Updating progress bar\n","            batch_iterator.set_postfix({f\"loss\": f\"{loss.item():6.3f}\"})\n","            \n","            writer.add_scalar('train loss', loss.item(), global_step)\n","            writer.flush()\n","            \n","            # Performing backpropagation\n","            loss.backward()\n","            \n","            # Updating parameters based on the gradients\n","            optimizer.step()\n","            \n","            # Clearing the gradients to prepare for the next batch\n","            optimizer.zero_grad()\n","            \n","            global_step += 1 # Updating global step count\n","            \n","        # We run the 'run_validation' function at the end of each epoch\n","        # to evaluate model performance\n","        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n","         \n","        # Saving model\n","        model_filename = get_weights_file_path(config, f'{epoch:02d}')\n","        # Writting current model state to the 'model_filename'\n","        torch.save({\n","            'epoch': epoch, # Current epoch\n","            'model_state_dict': model.state_dict(),# Current model state\n","            'optimizer_state_dict': optimizer.state_dict(), # Current optimizer state\n","            'global_step': global_step # Current global step \n","        }, model_filename)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device cuda\n","Max length of source sentence: 309\n","Max length of target sentence: 274\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 00: 100%|██████████| 3638/3638 [17:58<00:00,  3.37it/s, loss=5.557]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: Would you like to see her?\n","TARGET: Vuoi vederla?\n","PREDICTED: E che cosa ?\n","--------------------------------------------------------------------------------\n","SOURCE: It was to his interest that every labourer should get through as much work as possible and at the same time give his mind to it, not injuring the winnowing machine, the horse-rake, or the threshing machine, but working intelligently. The labourer wished to work in the pleasantest way possible, with intervals of rest, and especially to think unconcernedly about other things without having to reason.\n","TARGET: Egli aveva interesse a che ogni lavoratore rendesse quanto più possibile, che non si distraesse, che badasse a non rompere i vagli, che riflettesse a quello che faceva; il lavoratore, invece, aveva interesse a lavorare nel modo più piacevole possibile, con respiro, e soprattutto senza preoccupazione, lasciandosi andare, senza pensare. E proprio in quell’estate Levin aveva constatato ciò ad ogni passo.\n","PREDICTED: Il signor Rochester era un ’ altra , e che non era un ’ altra , e che non era un ’ altra , e che non era un ’ altra , e non era un ’ altra , e che non era un ’ altra , e non era fatto che non era più più più più di me , e non era più più più più più , e che non era più più più più più di me non era fatto di me .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 01: 100%|██████████| 3638/3638 [16:39<00:00,  3.64it/s, loss=5.348]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: By remaining in the service I lose nothing.\n","TARGET: Rimanendo in servizio non perdo nulla.\n","PREDICTED: a questo momento , ma non mi .\n","--------------------------------------------------------------------------------\n","SOURCE: She glanced at Dolly, but not pausing for a reply continued:\n","TARGET: Guardò per un attimo Dolly, ma senza aspettare risposta, continuò.\n","PREDICTED: Ella guardò , ma non era un po ’ di nuovo , ma non era un po ’ di .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 02: 100%|██████████| 3638/3638 [15:45<00:00,  3.85it/s, loss=5.404]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: I meditated wonderingly on this incident; but gradually quitting it, as I found it for the present inexplicable, I turned to the consideration of my master's manner to myself.\n","TARGET: Vi riflettei per un istante, ma poi, trovando inesplicabile quell'incidente, vi rinunziai e mi misi allora a pensare alle maniere del signor Rochester.\n","PREDICTED: un uomo che mi , ma mi , ma mi , mi la mia vita , mi in quel momento che mi .\n","--------------------------------------------------------------------------------\n","SOURCE: First, I had no plough to turn up the earth—no spade or shovel to dig it. Well, this I conquered by making me a wooden spade, as I observed before; but this did my work but in a wooden manner; and though it cost me a great many days to make it, yet, for want of iron, it not only wore out soon, but made my work the harder, and made it be performed much worse.\n","TARGET: Primieramente io non aveva aratro per volger la terra; non una vanga per vangarla, se non quella ch’io m’avea fatta di legno come osservai precedentemente; ma questa serviva al mio lavoro come può servire una vanga di legno, nè fatica o tempo impiegati per fabbricarmela fecero sì che mancando del ferro, non si logorasse ben presto, e rendesse i lavori eseguiti con essa e più penosi e più imperfetti. Pure mi rassegnai a valermi di ciò che aveva, e la peggiore riuscita non giunse a disanimarmi.\n","PREDICTED: Io non mi a , nè per la mia vita , non mi , ma per , ma per , ma per , ma per , ma non mi , ma non mi , ma non mi , ma non mi , ma non poteva , ma non mi più di più .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 03: 100%|██████████| 3638/3638 [16:03<00:00,  3.78it/s, loss=5.089]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: My eyes were covered and closed: eddying darkness seemed to swim round me, and reflection came in as black and confused a flow.\n","TARGET: La vista mi si oscurò, mi pareva che le tenebre mi circondassero, i miei pensieri si facevano confusi.\n","PREDICTED: La mia testa si e mi il capo .\n","--------------------------------------------------------------------------------\n","SOURCE: After that, feeling rather weak, he sat down on a bench in the yard and began demonstrating to Yashvin Russia's superiority to Prussia, especially in cavalry charges, and the carousal quieted down for a moment.\n","TARGET: Dopo, il comandante del reggimento, già infiacchito, sedette su di una panca nel cortile e cominciò a dimostrare a Jašvin la superiorità della Russia sulla Prussia, specie nell’attacco di cavalleria, e per un momento la baldoria si chetò.\n","PREDICTED: Dopo aver paura , un ’ espressione di cui si , si fermò in un angolo e si mise a guardare la carrozza , e , dopo aver preso la conversazione , si e si .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 04: 100%|██████████| 3638/3638 [18:47<00:00,  3.23it/s, loss=3.777]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: I'm never sure what I'm going to be, from one minute to another!\n","TARGET: Non so mai che diventerò da un minuto all'altro!\n","PREDICTED: Non posso dire che cosa devo fare , ma ora , dopo , a un tratto , un ’ altra .\n","--------------------------------------------------------------------------------\n","SOURCE: 'I?\n","TARGET: — Io?\n","PREDICTED: — Io ?\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 05: 100%|██████████| 3638/3638 [17:17<00:00,  3.51it/s, loss=4.280]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: Dolly, who had inherited her father's gift of putting things humorously, made Varenka collapse with laughter when she related for the third or fourth time, with ever fresh humorous additions, how she was just putting on some new ribbons in the visitor's honour, and was about to go into the drawing-room, when suddenly she heard the clatter of the old cart.\n","TARGET: E Dolly, che aveva ricevuto dal padre l’arte di raccontare le cose con spirito, faceva morir dal ridere Varen’ka, quando per la terza o quarta volta, sempre con nuove aggiunte umoristiche, raccontava come, proprio mentre lei si accingeva a mettersi dei nuovi nastri in omaggio all’ospite, e stava per uscire in salotto, ecco che, all’improvviso, aveva sentito il rumore della carretta.\n","PREDICTED: Dolly , che aveva il padre di Dar ’ ja Aleksandrovna , aveva preso la moglie di Varen ’ ka , quando Varen ’ ka , quando parlava con lei , o come se fosse stata stata la prima volta , come se fosse stata stata con i tre giorni di sotto al vecchio , aveva preso a chiamare il vecchio principe , era venuta a guardare il vecchio con un tratto , quando si era seduto in un tratto di sotto il vecchio maresciallo del governatorato .\n","--------------------------------------------------------------------------------\n","SOURCE: For this purpose, that I might do everything with discretion and consideration, I fitted up a little mast in my boat, and made a sail too out of some of the pieces of the ship’s sails which lay in store, and of which I had a great stock by me.\n","TARGET: A tal fine, per fare tutte le mie cose ponderatamente, adattai un piccolo albero alla mia navicella, formandogli una vela con alcuni pezzi di vele del vascello naufragalo de’ quali aveva una buona quantità presso di me.\n","PREDICTED: Per quanto io mi , io mi e a , io in un ’ isola , io mi in un ’ isola , e a bordo del mare , mi posi in mare a bordo del vascello naufragato , ove io m ’ avea un ’ acqua .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 06: 100%|██████████| 3638/3638 [18:07<00:00,  3.35it/s, loss=3.987]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: In this kind of dress I went my new journey, and was out five or six days.\n","TARGET: Non avendo questa volta la piroga che mi desse fastidio, presi per terra una via più corta, per giungere all’altura ov’era salito dianzi.\n","PREDICTED: A questo vestito di seta mi feci tornare a casa , e fui vicino a noi o sei giorni .\n","--------------------------------------------------------------------------------\n","SOURCE: It never occurred to him that by this action he was weakening himself, depriving himself of friends and of those who had thrown themselves into his lap, whilst he aggrandized the Church by adding much temporal power to the spiritual, thus giving it greater authority.\n","TARGET: Né si accorse, con questa deliberazione, che faceva sé debole, togliendosi li amici e quelli che se li erano gittati in grembo, e la Chiesa grande, aggiugnendo allo spirituale, che gli dà tanta autorità, tanto temporale.\n","PREDICTED: Non gli era mai accaduto questo , che era stato d ’ animo suo , e aveva dato uno stato di sé e di quelle sue azioni , che aveva dato a ' sua sudditi , mentre la Chiesa aveva , la fede , come per la fede , la fede .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 07: 100%|██████████| 3638/3638 [17:30<00:00,  3.46it/s, loss=3.917]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: He understood all the different kinds and was able to draw inspiration from all, but he could not imagine that it is possible to be quite ignorant of the different kinds of art and to be inspired directly by what is in one's own soul, regardless of whether what one paints belongs to any particular school.\n","TARGET: Intendeva qualsiasi genere, e poteva ispirarsi a questo e a quello; non immaginava che si potesse del tutto ignorare quali generi di pittura esistessero e che ci si potesse ispirare direttamente a quello che c’è nell’anima, senza preoccuparsi se quello che si è dipinto appartiene a un certo determinato genere.\n","PREDICTED: Sentiva tutte le nuove correnti e di umore , ma per questo non poteva non poter essere altrimenti che si può essere potuto essere della vita e dell ’ arte , e che per un ’ arte e di un ’ azienda è accaduto in un ’ anima di simile a quello che si può comprare un ’ idea di .\n","--------------------------------------------------------------------------------\n","SOURCE: 'The Princess will be very sorry.'\n","TARGET: — La principessa se ne rammaricherà molto.\n","PREDICTED: — La principessa sarà molto contenta .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 08: 100%|██████████| 3638/3638 [16:33<00:00,  3.66it/s, loss=4.293]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: Daily He announces more distinctly,--'Surely I come quickly!' and hourly I more eagerly respond,--'Amen; even so come, Lord Jesus!'\"\n","TARGET: Avanzo rapidamente, e ogni ora che scorre rispondo con maggior ardore: — Amen, venite, Signore Gesù!\n","PREDICTED: Ogni volta che più egli si considerava , tanto più strana e più spesso mi diceva , con piacere che il colpevole fosse ancora un ' altra cosa : “ Signore !\n","--------------------------------------------------------------------------------\n","SOURCE: The wish to acquire is in truth very natural and common, and men always do so when they can, and for this they will be praised not blamed; but when they cannot do so, yet wish to do so by any means, then there is folly and blame.\n","TARGET: È cosa veramente molto naturale et ordinaria desiderare di acquistare; e sempre, quando li uomini lo fanno che possano, saranno laudati, o non biasimati; ma, quando non possono, e vogliono farlo in ogni modo, qui è l’errore et il biasimo.\n","PREDICTED: E per chiarire la verità , è molto difficile e ' principi felici , e li uomini hanno sempre amici , e non possono , ma quando si con loro , ma non si può non fare con loro , e ' tempi avversi , e ' è .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 09: 100%|██████████| 3638/3638 [15:43<00:00,  3.86it/s, loss=2.612]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: The old-fashioned chairs were very bright, and the walnut-wood table was like a looking-glass.\n","TARGET: Le antiche sedie eran lucenti e la tavola di noce pareva uno specchio.\n","PREDICTED: Il vecchio di carrozze erano fra le sedie e le sedie , come un tavolino , era un tavolino su un tavolino .\n","--------------------------------------------------------------------------------\n","SOURCE: Adele brought her stool to my feet; ere long she touched my knee. \"What is it, Adele?\"\n","TARGET: Adele portò il panchettino davanti a me, e poco dopo mi toccò il ginocchio. — Che cosa volete? — le domandai.\n","PREDICTED: La signorina Miller le fece venire in camera mia , e la chiusi , perché mi domandò : — Che cosa è qui ?\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 10: 100%|██████████| 3638/3638 [15:43<00:00,  3.86it/s, loss=2.998]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: 'Perhaps he has gone out into the hall; he was walking about there just now.\n","TARGET: — È forse uscito nell’ingresso, non faceva che camminare.\n","PREDICTED: — Può darsi che è andato in anticamera , perché è arrivato fino a ora .\n","--------------------------------------------------------------------------------\n","SOURCE: I sought the orchard, driven to its shelter by the wind, which all day had blown strong and full from the south, without, however, bringing a speck of rain.\n","TARGET: Mi diressi verso il pomario, per trovar riparo contro il vento di mezzogiorno che aveva soffiato fin dalla mattina, senza procurarci il sollievo della pioggia.\n","PREDICTED: Cercai un posticino alla brezza della vento coperto di vento , che tutto il vento della giornata , e su un vento coperto di miglio all ’ incirca .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 11: 100%|██████████| 3638/3638 [15:42<00:00,  3.86it/s, loss=3.565]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: \"Do you forgive me, Jane?\"\n","TARGET: — Mi perdonate, Jane?\n","PREDICTED: — Lo , Jane ?\n","--------------------------------------------------------------------------------\n","SOURCE: When she got back to the Cheshire Cat, she was surprised to find quite a large crowd collected round it: there was a dispute going on between the executioner, the King, and the Queen, who were all talking at once, while all the rest were quite silent, and looked very uncomfortable.\n","TARGET: Ma con sorpresa trovò una gran folla raccolta intorno al Ghignagatto; il Re, la Regina e il carnefice urlavano tutti e tre insieme, e gli altri erano silenziosi e malinconici.\n","PREDICTED: Quando la Regina fu terminata , ( era ) si vide un nuovo tratto alla folla ) e si sedettero fra il Re ) e il Re inforcò con tutta la Regina , mentre parlava di tutte le altre cose .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 12: 100%|██████████| 3638/3638 [15:42<00:00,  3.86it/s, loss=2.647]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: I suppose he had considered that these were all the governess would require for her private perusal; and, indeed, they contented me amply for the present; compared with the scanty pickings I had now and then been able to glean at Lowood, they seemed to offer an abundant harvest of entertainment and information.\n","TARGET: Aveva supposto che questo dovesse bastare a una istitutrice.\n","PREDICTED: Credo che si sentisse il fatto che tutti quelli che potessero , ed l ' agitazione del mio linguaggio ; perchè mi con tanta violenza come ne avevo giudicato il più facile ; poi mi la storia delle mie , credo che la a Lowood e il cibo .\n","--------------------------------------------------------------------------------\n","SOURCE: 'I don't expect you to understand me and my feelings, as an affectionate man would; but I did expect ordinary delicacy,' she said.\n","TARGET: — Io non m’aspetto che vi ricordiate di me, dei miei sentimenti, come se ne può ricordare una persona che ama, ma mi aspetto soltanto un po’ di delicatezza — ella aveva detto.\n","PREDICTED: — Non capisco , non mi a me e per me come un uomo che mi sarebbe parso intelligente ; ma per quanto è intelligente ?\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 13: 100%|██████████| 3638/3638 [16:46<00:00,  3.61it/s, loss=2.593]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: But Dolly, on receiving the telegram, only sighed over the rouble it had cost, and understood that it had been sent toward the end of a dinner.\n","TARGET: Dar’ja Aleksandrovna, invece, ricevuto il telegramma, sospirò soltanto per il rublo del telegramma e capì che la cosa era avvenuta alla fine d’un pranzo.\n","PREDICTED: Ma Dolly , nel telegramma , nel telegramma , sospirò soltanto in dieci rubli , dicendo che si doveva avere un pranzo verso la fine del pranzo .\n","--------------------------------------------------------------------------------\n","SOURCE: 'You are growing younger every day, Bondarenko!' he remarked to the ruddy-faced, smart-looking sergeant-major, serving for a second term, who stood just in front of him.\n","TARGET: — Tu diventi sempre più giovane, Bondarenko — disse rivolto a un ben fatto, rubicondo maresciallo che era stato richiamato in servizio per la seconda volta, e che stava diritto davanti a lui.\n","PREDICTED: — Voi sempre ogni giorno , signori — disse , guardando il viso accigliato , un viso infantile e accostandosi al passo dei bambini , che prima di lui era stato in lui .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 14: 100%|██████████| 3638/3638 [18:28<00:00,  3.28it/s, loss=3.070]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: It is very old, and it was very strong and great once.\n","TARGET: È città antichissima, e una volta era assai forte e grande.\n","PREDICTED: È molto vecchio , e molto ebbe grande e grande .\n","--------------------------------------------------------------------------------\n","SOURCE: \"No, I didn't,\" grunted Harris; \"I said twelve.\n","TARGET: — No, non è vero — grugnì Harris. — Ho detto dodici.\n","PREDICTED: — No , non ho mai pensato a Landau , — dissi Harris .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 15: 100%|██████████| 3638/3638 [17:41<00:00,  3.43it/s, loss=2.574]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: And the leaves of the trees that grew in the wood were very dark and thick, so that no ray of light came through the branches to lighten the gloom and sadness.\n","TARGET: E le foglie degli alberi che crescevano nella foresta erano oscurissime e folte tanto che non un raggio di luce filtrava a traverso i rami ad attenuare la tenebra e la tristezza.\n","PREDICTED: E le foglie gli alberi erano l ' uno all ' altro lato , così forte , così forte , che non si era acceso , e il fragore di quell ' aria s ' .\n","--------------------------------------------------------------------------------\n","SOURCE: She filled up the hiatus his silence left by a reply of her own.\n","TARGET: E vedendo che Saint-John non rispondeva, riprese:\n","PREDICTED: Ella si accostò al silenzio del suo silenzio , e immediatamente per un attimo di rimprovero .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 16: 100%|██████████| 3638/3638 [17:24<00:00,  3.48it/s, loss=2.858]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: 'Perhaps you would not if you were not successful,' said Vronsky.\n","TARGET: — Forse non lo confesseresti, se non avessi successo — disse Vronskij.\n","PREDICTED: — Può darsi che tu non sareste per te e per la stessa maniera — disse Vronskij .\n","--------------------------------------------------------------------------------\n","SOURCE: 'I shall still get angry with Ivan the coachman in the same way, shall dispute in the same way, shall inopportunely express my thoughts; there will still be a wall between my soul's holy of holies and other people; even my wife I shall still blame for my own fears and shall repent of it. My reason will still not understand why I pray, but I shall still pray, and my life, my whole life, independently of anything that may happen to me, is every moment of it no longer meaningless as it was before, but has an unquestionable meaning of goodness with which I have the power to invest it.'\n","TARGET: Mi arrabbierò sempre alla stessa maniera contro Ivan il cocchiere, sempre alla stessa maniera discuterò, esprimerò a sproposito le mie idee, ci sarà lo stesso muro fra il tempio dell’anima mia e quello degli altri, e perfino mia moglie accuserò sempre alla stessa maniera del mio spavento e ne proverò rimorso; sempre alla stessa maniera, non capirò con la ragione perché prego e intanto pregherò, ma la mia vita adesso, tutta la mia vita, indipendentemente da tutto quello che mi può accadere, ogni suo attimo, non solo non è più senza senso, come prima, ma ha un indubitabile senso di bene, che io ho il potere di trasfondere in essa!”.\n","PREDICTED: — Io sarò forte con la stessa via in cui la stessa visione , le grida e dice : la mia fantasia ha sempre anima verrà ancora un ' anima ; ma la mia vita è stata legata da me , sempre anche i miei compagni , e io dovrò vivere ancora di questi , non parlo la ragione ; ma la mia vita è ancora , e non sappiamo che siamo in sogno , io sono , la mia vita , l ’ esistenza che è fatta , come accordo senza senso di tutti i miei sentimenti , sono necessari cristiani , cioè , la colpa di me , cioè , sono senza senso di me .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 17: 100%|██████████| 3638/3638 [16:41<00:00,  3.63it/s, loss=2.040]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: 'Till then, and that may be always, you are happy and tranquil.\n","TARGET: — Fino ad allora, e potrebbe essere sempre, voi sarete felici e tranquilli.\n","PREDICTED: — Bisogna che non siamo sempre contenti di nuovo e di nuovo siete tranquillo .\n","--------------------------------------------------------------------------------\n","SOURCE: Now act as you please: write and contradict my assertion--expose my falsehood as soon as you like.\n","TARGET: Ora fate quello che volete, scrivete per contraddire la mia asserzione, sbugiardatemi, dite tutto quello che vi piace.\n","PREDICTED: Vi fa piacere , vi prego , vi prego , vieni a mente ; la mia ragione è sì fuor di me .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 18: 100%|██████████| 3638/3638 [17:40<00:00,  3.43it/s, loss=2.227]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: \"That is no answer; or rather it is a very irritating, because a very evasive one. Reply clearly.\"\n","TARGET: — Non è una risposta, o almeno è irritante, perché evasiva; rispondete chiaro.\n","PREDICTED: — Non si tratta di una risposta , o almeno piuttosto , perché sono molto contenta di un ' espressione severa .\n","--------------------------------------------------------------------------------\n","SOURCE: I believe there were some misunderstandings between them.\n","TARGET: Credo che vi fossero frequenti dispute fra i due fratelli.\n","PREDICTED: Credo che ci fossero tutti e tre .\n"]},{"name":"stderr","output_type":"stream","text":["Processing epoch 19: 100%|██████████| 3638/3638 [17:54<00:00,  3.39it/s, loss=2.086]\n"]},{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------\n","SOURCE: Annushka was already dozing, her broad hands, with a hole in one of the gloves, holding the red bag on her lap.\n","TARGET: Annuška già sonnecchiava, tenendo la sacca rossa sulle ginocchia con le mani larghe nei guanti, uno dei quali era bucato.\n","PREDICTED: Annuška si mangiava la , con le mani in un estremo senso , le braccia le braccia incrociate e morbide sul petto .\n","--------------------------------------------------------------------------------\n","SOURCE: \"Why did I never hear of this?\" I asked.\n","TARGET: — Perché non ho saputo nulla di ciò? — domandai.\n","PREDICTED: — Perché non ho mai saputo mai ? — domandai .\n"]}],"source":["if __name__ == '__main__':\n","    warnings.filterwarnings('ignore') # Filtering warnings\n","    config = get_config() # Retrieving config settings\n","    train_model(config) # Training model with the config arguments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
